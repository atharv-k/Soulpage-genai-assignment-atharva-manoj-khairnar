import os
from dotenv import load_dotenv
import streamlit as st
from langchain_groq import ChatGroq
from typing import TypedDict, List, Annotated
from langgraph.graph.message import add_messages
from langgraph.graph import StateGraph, END
from langchain_core.tools import Tool
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_classic.agents import create_tool_calling_agent
from langchain_classic.agents import AgentExecutor
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage

load_dotenv()
if "GROQ_API_KEY" not in os.environ:
    st.error("Please set your GROQ_API_KEY in the .env file or environment variables.")
    st.stop()
groq_api_key = os.getenv("GROQ_API_KEY")

# --- 2. Initialize Components ---

# A. Language Model
llm = ChatGroq(
    model="llama-3.1-8b-instant",
    api_key=groq_api_key
) 

# B. Tools 
# DuckDuckGoSearchRun: the tool wrapper for a free web search.
search = DuckDuckGoSearchRun()
tools = [
    Tool(
        name="DuckDuckGoSearch",
        func=search.run,
        description="Useful for when you need to answer questions about current events, factual information, or things you don't know.",
    )
]

# 2a. Define the Data Collector Agent
collector_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a specialized **Data Collector Agent**. Your sole purpose is to gather the LATEST, "
            "relevant information (news headlines, stock performance) for the company requested. "
            "You MUST use the provided search tool. Gather the information and return it as raw text.",
        ),
        MessagesPlaceholder(variable_name="messages"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ]
)

collector_agent = create_tool_calling_agent(llm, tools, collector_prompt)
collector_executor = AgentExecutor(agent=collector_agent, tools=tools, verbose=True)

# 2b. Define the Data Collector Node Function

# This defines the shared state object
class AgentState(TypedDict):
    """
    Represents the state of our multi-agent system.
    """
    # The initial input (e.g., "Apple")
    company_name: str
    # Raw data collected by Agent 1
    raw_data: str
    # Final summary/insights generated by Agent 2
    final_report: str
    # A list of messages for context/history
    messages: Annotated[List[tuple], add_messages]

def run_data_collector(state: AgentState):
    print("---EXECUTING DATA COLLECTOR---")
    company = state["company_name"]
    # The message sent to the agent's prompt
    input_message = f"Fetch the latest news and stock price performance for the company: {company}. Be brief and factual."

    result = collector_executor.invoke({"messages": [("user", input_message)], "company_name": company})
    
    # Extracting the output and updating the state
    raw_data = result["output"]
    
    return {
        "raw_data": raw_data,
        "messages": [("user", f"Raw data collected for {company}: {raw_data}")]
    }

# 3a. Define the Analyst Agent Node Function
def run_analyst(state: AgentState):
    print("---EXECUTING ANALYST---")
    company = state["company_name"]
    raw_data = state["raw_data"]

    # Constructing a detailed prompt for the Analyst
    analysis_prompt = f"""
    You are a specialized **Company Intelligence Analyst**.
    Your task is to analyze the following raw data collected about {company}.
    
    **Raw Data:**
    {raw_data}

    **Your Report MUST contain:**
    1. A concise **Summary** of the current situation.
    2. **Key Insights** derived from the data (e.g., "The stock is up 5% on positive earnings news").
    3. At least one potential **Risk Factor** based on the news (e.g., "Regulatory investigation is a risk factor").
    4. **Sentiment Score** (Positive/Neutral/Negative).
    
    Format the report professionally.
    """

    # We use a simple LLM call here, as no tools are needed
    analysis_message = HumanMessage(content=analysis_prompt)
    
    response = llm.invoke([analysis_message])
    final_report = response.content

    return {
        "final_report": final_report,
        "messages": [("assistant", f"Final report generated by Analyst: {final_report}")]
    }

# 4a. Build the Graph
workflow = StateGraph(AgentState)

# Add the nodes (the agents)
workflow.add_node("data_collector", run_data_collector)
workflow.add_node("analyst", run_analyst)

# Set the entry point (the first agent to run)
workflow.set_entry_point("data_collector")

# Define the sequence of execution
# 1. After Data Collector, transition to Analyst
workflow.add_edge("data_collector", "analyst")

# 2. After Analyst, the task is complete (END)
workflow.add_edge("analyst", END)

# Compile the graph
app = workflow.compile()

# 4b. Define the main execution function
def generate_company_report(company_name: str):
    """Executes the multi-agent workflow."""
    
    # 1. Define the initial state for the run
    initial_state = {
        "company_name": company_name,
        "raw_data": "",
        "final_report": "",
        "messages": [("user", f"Start report generation for: {company_name}")]
    }
    
    print(f"\n*** STARTING REPORT FOR: {company_name} ***")
    
    # 2. Invoke the compiled LangGraph app
    # We run it until it reaches the END node
    final_state = app.invoke(initial_state)
    
    print("\n*** WORKFLOW COMPLETE ***")
    print("\n--- FINAL REPORT ---\n")
    print(final_state["final_report"])
    
    # 3. **Memory/Context Check:** # The 'messages' list in the final state contains the entire conversation 
    # history, which is the mechanism for maintaining context between agents.
    #print("\n--- CONTEXT/HISTORY (MEMORY CHECK) ---")
    #for msg_type, msg_content in final_state["messages"]:
    #    print(f"[{msg_type.upper()}]: {msg_content[:100]}...")

    return final_state["final_report"]

st.title("Company Intelligence Agentic System")

company_input = st.text_input("Enter Company Name (e.g., 'Google', 'Netflix')")

if st.button("Generate Report") and company_input:
    with st.spinner("Agents are collaborating to gather data and generate the report..."):
        # The LangGraph execution happens here
        final_report = generate_company_report(company_input) 
        
    st.subheader(f"Analysis Report for {company_input}")
    st.markdown(final_report) # Displays the formatted output